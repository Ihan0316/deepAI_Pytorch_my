{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:05:29.672571Z",
     "start_time": "2025-03-24T03:05:29.670116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import zipfile\n",
    "import cv2\n",
    "\n",
    "# 작업 경로 설정 (로컬 경로)\n",
    "base_path = \"/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8\"\n",
    "os.makedirs(base_path, exist_ok=True)\n"
   ],
   "id": "f68ea0c3fcae5f6d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:05:29.689606Z",
     "start_time": "2025-03-24T03:05:29.687322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ultralytics 설치 (터미널에서 실행 필요)\n",
    "# pip install ultralytics\n",
    "\n",
    "# YOLO 설치 확인\n",
    "# YOLO.checks()\n"
   ],
   "id": "7a46d3e9a4aa0127",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:05:51.847396Z",
     "start_time": "2025-03-24T03:05:29.695460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터셋 다운로드 및 압축 해제\n",
    "dataset_url = \"https://public.roboflow.com/ds/EUBO4ATjbt?key=dnYrjDbMEB\"\n",
    "zip_path = os.path.join(base_path, \"Aquarium_DataSet.zip\")\n",
    "extract_path = os.path.join(base_path, \"Aquarium_DataSet\")\n",
    "\n",
    "# wget 대신 urllib 사용\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(dataset_url, zip_path)\n",
    "\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(extract_path)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(f\"Aquarium_DataSet 압축 해제가 완료되었습니다. 폴더 경로: {extract_path}\")\n"
   ],
   "id": "5733f3ddf98e9730",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aquarium_DataSet 압축 해제가 완료되었습니다. 폴더 경로: /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/Aquarium_DataSet\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:05:51.854371Z",
     "start_time": "2025-03-24T03:05:51.851744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# YAML 파일 생성\n",
    "yaml_path = os.path.join(extract_path, \"Aquarium_Data.yaml\")\n",
    "data = {\n",
    "    'train': os.path.join(extract_path, \"train\", \"images\") + \"/\",\n",
    "    'val': os.path.join(extract_path, \"valid\", \"images\") + \"/\",\n",
    "    'test': os.path.join(extract_path, \"test\", \"images\") + \"/\",\n",
    "    'nc': 7,\n",
    "    'names': ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n",
    "}\n",
    "\n",
    "import yaml\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "print(\"YAML 파일 생성 완료:\", yaml_path)\n"
   ],
   "id": "8d249cd362f37451",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML 파일 생성 완료: /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/Aquarium_DataSet/Aquarium_Data.yaml\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:15:26.298873Z",
     "start_time": "2025-03-24T03:05:51.905097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 사전 학습된 YOLO 모델 로드\n",
    "model = YOLO(\"yolov8n.pt\")  # 사전 학습된 모델 로드\n",
    "\n",
    "# 모델 학습\n",
    "results = model.train(\n",
    "    data=yaml_path,         # 데이터셋 구성 파일 경로\n",
    "    epochs=20,             # 학습 에포크 수\n",
    "    patience=30,            # 조기 종료 기준 에포크 수\n",
    "    batch=64,               # 배치 크기\n",
    "    imgsz=416,              # 입력 이미지 크기\n",
    "    project=base_path,      # 결과 저장 경로\n",
    "    name='modelresult',     # 프로젝트 이름\n",
    "    device=\"mps\"            # Apple Silicon GPU(MPS) 사용\n",
    ")\n",
    "\n",
    "print(f\"모델 학습 완료. 저장 경로: {results.save_dir}\")\n"
   ],
   "id": "1ca4da88e854c1e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:01<00:00, 4.46MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.95 🚀 Python-3.13.2 torch-2.6.0 MPS (Apple M4 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/Aquarium_DataSet/Aquarium_Data.yaml, epochs=20, time=None, patience=30, batch=64, imgsz=416, save=True, save_period=-1, cache=False, device=mps, workers=8, project=/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8, name=modelresult, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,012,213 parameters, 3,012,197 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/Aquarium_DataSet/train/labels... 448 images, 1 backgrounds, 0 corrupt: 100%|██████████| 448/448 [00:00<00:00, 3876.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mNew cache created: /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/Aquarium_DataSet/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/Aquarium_DataSet/valid/labels... 127 images, 0 backgrounds, 0 corrupt: 100%|██████████| 127/127 [00:00<00:00, 4171.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mval: \u001B[0mNew cache created: /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/Aquarium_DataSet/valid/labels.cache\n",
      "Plotting labels to /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1m/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult\u001B[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      8.59G      1.742       4.35      1.348        955        416: 100%|██████████| 7/7 [00:07<00:00,  1.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909    0.00196      0.142     0.0123    0.00861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      10.3G      1.666      4.086      1.248        693        416: 100%|██████████| 7/7 [00:09<00:00,  1.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:03<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909    0.00405      0.213     0.0335     0.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      11.4G      1.694      3.582      1.188        895        416: 100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909    0.00771      0.342     0.0505      0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      12.5G      1.725      2.875      1.177        866        416: 100%|██████████| 7/7 [00:14<00:00,  2.07s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909     0.0155      0.524      0.169     0.0848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      12.7G      1.689      2.486      1.179        807        416: 100%|██████████| 7/7 [00:11<00:00,  1.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909     0.0171      0.492      0.198      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      12.6G      1.664      2.276      1.184        749        416: 100%|██████████| 7/7 [00:13<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.502      0.104      0.239      0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      12.8G      1.618      2.054      1.151        652        416: 100%|██████████| 7/7 [00:14<00:00,  2.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.544      0.107      0.304      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      12.8G      1.597      1.842      1.147        678        416: 100%|██████████| 7/7 [00:16<00:00,  2.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909       0.72     0.0711       0.33      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      12.7G      1.583      1.716      1.155        706        416: 100%|██████████| 7/7 [00:15<00:00,  2.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:08<00:00,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.824     0.0866      0.365      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      12.8G      1.536      1.649      1.144        919        416: 100%|██████████| 7/7 [00:14<00:00,  2.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.797     0.0982      0.344      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20      12.7G      1.504      1.585      1.131        449        416: 100%|██████████| 7/7 [00:25<00:00,  3.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.731      0.078      0.298      0.156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      12.8G       1.46      1.523      1.114        443        416: 100%|██████████| 7/7 [00:25<00:00,  3.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.745      0.138      0.311      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      12.8G      1.436      1.451      1.103        559        416: 100%|██████████| 7/7 [00:27<00:00,  3.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:12<00:00, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.742      0.161      0.232      0.116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      12.8G       1.43      1.389      1.091        475        416: 100%|██████████| 7/7 [00:25<00:00,  3.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:11<00:00, 11.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.581      0.207      0.293      0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      12.9G       1.41      1.345      1.079        438        416: 100%|██████████| 7/7 [00:24<00:00,  3.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:12<00:00, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.632      0.217      0.257      0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20        13G      1.395      1.319      1.079        463        416: 100%|██████████| 7/7 [00:22<00:00,  3.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909        0.6      0.189      0.194       0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20        13G      1.394      1.262      1.065        498        416: 100%|██████████| 7/7 [00:24<00:00,  3.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909       0.51     0.0487     0.0755      0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      13.1G      1.347      1.223      1.054        405        416: 100%|██████████| 7/7 [00:22<00:00,  3.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:10<00:00, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.478     0.0576     0.0753     0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      13.1G      1.323       1.19      1.053        471        416: 100%|██████████| 7/7 [00:22<00:00,  3.17s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:09<00:00,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.606     0.0629     0.0823     0.0407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      13.2G      1.329      1.173      1.053        448        416: 100%|██████████| 7/7 [00:20<00:00,  2.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ NMS time limit 8.350s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:11<00:00, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.495      0.183      0.197      0.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.157 hours.\n",
      "Optimizer stripped from /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult/weights/best.pt...\n",
      "Ultralytics 8.3.95 🚀 Python-3.13.2 torch-2.6.0 MPS (Apple M4 Pro)\n",
      "Model summary (fused): 72 layers, 3,007,013 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        127        909      0.821     0.0866      0.365      0.201\n",
      "                  fish         63        459      0.903     0.0606      0.496      0.239\n",
      "             jellyfish          9        155          1     0.0326      0.817      0.463\n",
      "               penguin         17        104      0.667     0.0769      0.281      0.111\n",
      "                puffin         15         74          1          0     0.0404     0.0177\n",
      "                 shark         28         57      0.304      0.193      0.174     0.0859\n",
      "              starfish         17         27      0.871      0.185      0.387      0.252\n",
      "              stingray         23         33          1     0.0582      0.359      0.242\n",
      "Speed: 0.6ms preprocess, 2.1ms inference, 0.0ms loss, 16.4ms postprocess per image\n",
      "Results saved to \u001B[1m/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult\u001B[0m\n",
      "모델 학습 완료. 저장 경로: /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:15:26.363861Z",
     "start_time": "2025-03-24T03:15:26.311080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# YOLOv8 모델로 예측 실행 및 저장 경로 변경\n",
    "# 사용자 정의 YOLOv8 모델 로드\n",
    "model = YOLO(\"/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresult/weights/best.pt\")\n",
    "\n",
    "results = model.predict(\n",
    "    source='/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg',  # 테스트 이미지 경로\n",
    "    save=True,  # 결과 저장 활성화\n",
    "    save_dir='/Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresultimg/'  # 결과 저장 경로\n",
    ")\n",
    "\n",
    "print(f\"결과 이미지가 다음 경로에 저장되었습니다: /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresultimg/\")"
   ],
   "id": "e9c2e4d51c111d01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/IMG_2301_jpeg_jpg.rf.2c19ae5efbd1f8611b5578125f001695.jpg: 416x320 (no detections), 18.3ms\n",
      "Speed: 1.0ms preprocess, 18.3ms inference, 0.2ms postprocess per image at shape (1, 3, 416, 320)\n",
      "Results saved to \u001B[1mruns/detect/predict\u001B[0m\n",
      "결과 이미지가 다음 경로에 저장되었습니다: /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/modelresultimg/\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T03:15:26.374386Z",
     "start_time": "2025-03-24T03:15:26.367651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 비디오 예측 실행\n",
    "video_path = \"/Users/your_username/Documents/YOLOTest7/sample_video.mp4\"\n",
    "output_video = os.path.join(base_path, \"output_video.mp4\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file.\")\n",
    "    exit()\n",
    "\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model.predict(source=frame, save=False, conf=0.5)\n",
    "    annotated_frame = results[0].plot()\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f\"Detection completed. Output video saved at {output_video}\")\n"
   ],
   "id": "eacd27c9282c16e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Cannot open video file.\n",
      "Detection completed. Output video saved at /Users/ihanjo/Documents/K-Digital/deepAI_Pytorch_my/4-Yolov8/YOLOv8/output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"/Users/your_username/Documents/YOLOTest7/sample_video.mp4\"\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
